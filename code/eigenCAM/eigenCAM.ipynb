{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming directory structure \n",
    "# root\n",
    "# |___yolov5/*\n",
    "# |___MicronutrientDeficiencyData-1/*\n",
    "# |___best.pt\n",
    "# |___images/\n",
    "#       |___testimg.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qr yolov5/requirements.txt comet_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_path = './best.pt'\n",
    "model = torch.hub.load('./yolov5', 'custom', path=model_path, source='local')\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "target_layers = [model.model.model.model[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "import PIL\n",
    "from tqdm.auto import tqdm\n",
    "import shutil as sh\n",
    "from pathlib import Path\n",
    "import random\n",
    "from IPython.display import Image, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EigenCAM import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git\n",
    "!pip install grad-cam==1.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_grad_cam import EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, scale_cam_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "def parse_detections(results):\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    detections = detections.to_dict()\n",
    "    boxes, colors, names = [], [], []\n",
    "\n",
    "    for i in range(len(detections[\"xmin\"])):\n",
    "        confidence = detections[\"confidence\"][i]\n",
    "        if confidence < 0.2:\n",
    "            continue\n",
    "        xmin = int(detections[\"xmin\"][i])\n",
    "        ymin = int(detections[\"ymin\"][i])\n",
    "        xmax = int(detections[\"xmax\"][i])\n",
    "        ymax = int(detections[\"ymax\"][i])\n",
    "        name = detections[\"name\"][i]\n",
    "        category = int(detections[\"class\"][i])\n",
    "        color = COLORS[category]\n",
    "\n",
    "        boxes.append((xmin, ymin, xmax, ymax))\n",
    "        colors.append(color)\n",
    "        names.append(name)\n",
    "    return boxes, colors, names\n",
    "\n",
    "def draw_detections(boxes, colors, names, img):\n",
    "    for box, color, name in zip(boxes, colors, names):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (xmin, ymin),\n",
    "            (xmax, ymax),\n",
    "            color,\n",
    "            2)\n",
    "\n",
    "        cv2.putText(img, name, (xmin, ymin - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = 'images/testimg.jpg'\n",
    "img = np.array(Image.open(image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img, (640, 640))\n",
    "rgb_img = img.copy()\n",
    "img = np.float32(img) / 255\n",
    "transform = transforms.ToTensor()\n",
    "tensor = transform(img).unsqueeze(0)\n",
    "tensor.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EigenCAM image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = EigenCAM(model, target_layers)\n",
    "grayscale_cam = cam(tensor)[0, :, :]\n",
    "grayscale_cam = np.maximum(grayscale_cam, 0)\n",
    "grayscale_cam = grayscale_cam / grayscale_cam.max()\n",
    "cam_image = show_cam_on_image(rgb_img / 255.0, grayscale_cam, use_rgb=True)\n",
    "\n",
    "Image.fromarray(cam_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving EigenCAM image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('EigenCAM-image.jpg',cv2.cvtColor(cam_image, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
